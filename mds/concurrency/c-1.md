#   ConcurrentHashMap

##  为什么使用ConcurrentHashMap？

-   线程不安全的HashMap。在多线程下，对HashMap进行put操作会出现死循环。
-   HashTable的效率不高。一个线程在进行读写的时候，其他线程只能等待，其性能可想而知。

##  ConcurrentHashMap的原理

在ConcurrentHashMap中，有多个ReentrantLock，每一把锁都储存着一部分的数据。当多线程访问容器里不同数据段的时候，线程间就不会存在锁竞争。

##  ConcurrentHashMap的结构

**ConcurrentHashMap** 是由 **Segment** 数组结构和 **HashEntry** 数组结构组成。

-   Segment是ReentrantLock，在ConcurrentHashMap中扮演锁的角色。
-   HashEntry则用于 **储存** 键值对数据。

![](/imgs/concurrency/c-1-1.png)

## JDK1.7
-   [ConcurrentHashMap的初始化](#user-content-init-jdk7)
-   [put方法](#user-content-put-jdk7)
    -   [初始化Segment](#user-content-init-segement-jdk7)
    -   [获取链表：entryForHash](#user-content-get-entry-jdk7)
    -   [获取读写锁：scanAndLockForPut](#user-content-get-reentrantlock-jdk7)
    -   [扩容：rehash](#user-content-rehash-jdk7)
    -   [get方法](#user-content-get-jdk7)
    -   [定位Segment](#user-content-position-segment)
    -   [总结](#user-content-jdk7-summary)

## <a id="init-jdk7">ConcurrentHashMap的初始化</a>

![](/imgs/concurrency/c-1-2.png)

我们就从ConcurrentHashMap的空构造方法开始深入了解其初始化过程。

```java
static final int DEFAULT_INITIAL_CAPACITY = 16;

static final float DEFAULT_LOAD_FACTOR = 0.75f;

static final int DEFAULT_CONCURRENCY_LEVEL = 16;

public ConcurrentHashMap() {
    this(DEFAULT_INITIAL_CAPACITY, DEFAULT_LOAD_FACTOR, DEFAULT_CONCURRENCY_LEVEL);
}
```

接着来看一下，**ConcurrentHashMap(int, float, int)** 初始化了哪些变量。

```java
public ConcurrentHashMap(int initialCapacity,float loadFactor,int concurrencyLevel) {
    if (!(loadFactor > 0) || initialCapacity < 0 || concurrencyLevel <= 0)
        throw new IllegalArgumentException();
    //  并发最大的等级为 2^16 = 65536
    if (concurrencyLevel > MAX_SEGMENTS)
        concurrencyLevel = MAX_SEGMENTS;
    //  Find power-of-two sizes best matching arguments

    int sshift = 0;
    //  ssize是Segment数组的长度，为2^n
    int ssize = 1;
    while (ssize < concurrencyLevel) {
        ++sshift;
        ssize <<= 1;
    }

    //  默认的concurrencyLevel为16
    //  sshift为4
    //  ssize为16
    //  segmentShift为28
    //  segmentMask为15
    this.segmentShift = 32 - sshift;
    this.segmentMask = ssize - 1;

    //  初始容量initialCapacity是用从来设置整个map的大小，最大为2^30
    if (initialCapacity > MAXIMUM_CAPACITY)
        initialCapacity = MAXIMUM_CAPACITY;

    //  c为ssize的倍数，且c*ssize >= initialCapacity。
    int c = initialCapacity / ssize;
    if (c * ssize < initialCapacity)
        ++c;

    //  cap为每个Segment可分配的链表个数，最少每个segment可以放2个链表，且链表的个数为2^n(n >= 1)。
    int cap = MIN_SEGMENT_TABLE_CAPACITY;
    while (cap < c)
        cap <<= 1;

    // create segments and segments[0]
    Segment<K,V> s0 =
        new Segment<K,V>(loadFactor, (int)(cap * loadFactor),
                            (HashEntry<K,V>[])new HashEntry[cap]);
    Segment<K,V>[] ss = (Segment<K,V>[])new Segment[ssize];

    // 往数组写入 segment[0]
    UNSAFE.putOrderedObject(ss, SBASE, s0); // ordered write of segments[0]
    this.segments = ss;
}
```

-   初始化三个变量：
    -   段偏移量segementShift
    -   段掩码segementMask
    -   segment数组(不可扩容)
    -   segment[0]

segment数组的长度是由 `ssize` 来决定的其长度的。 `ssize` 是由concurrencyLevel(并发等级) 来决定。 这里的concurrencyLevel为16,所以 `sshift` 为4， `ssize` 为16，即这里的segment数组的长度为16，  `segmentShift` 为28， `segmentMask` 为15。

## <a id="put-jdk7">put</a>

```java
public V put(K key, V value) {
    Segment<K,V> s;

    //  value不能为null
    if (value == null)
        throw new NullPointerException();
    
    //  计算key的哈希码
    int hash = hash(key);

    int j = (hash >>> segmentShift) & segmentMask;
    if ((s = (Segment<K,V>)UNSAFE.getObject(segments, (j << SSHIFT) + SBASE)) == null) //  in ensureSegment
        // 初始化segment[j]
        s = ensureSegment(j);
    
    //  往初始化的segment里面添加节点
    return s.put(key, hash, value, false);
}
```

第一层，根据hash值很快就能找到相应的segment，之后就是segment内部的put操作。

```java
final V put(K key, int hash, V value, boolean onlyIfAbsent) {
    // 先获取该segment的独占锁，稍后会详解
    HashEntry<K,V> node = tryLock() ? null : scanAndLockForPut(key, hash, value);
    V oldValue;
    try {
        //  这个table就是前面构造函数中初始化的segment[j]里面的数组长度。
        HashEntry<K,V>[] tab = table;
        //  再利用hash，求该key所应该存放的数组下标位置
        int index = (tab.length - 1) & hash;
        //  获取index值下所对应的链表的表头
        HashEntry<K,V> first = entryAt(tab, index);
        //  下面进行是对链表存在和链表不存在的情况下，进行put操作
        for (HashEntry<K,V> e = first;;) {
            //  当链表存在时
            if (e != null) {
                K k;
                //  如果key已经存在，将已存在的值返回。同时将新的value覆盖掉旧的value。
                if ((k = e.key) == key ||
                    (e.hash == hash && key.equals(k))) {
                    oldValue = e.value;
                    if (!onlyIfAbsent) {
                        e.value = value;
                        ++modCount;
                    }
                    break;
                }

                //  遍历链表下一个
                e = e.next;
            }
            else {
                //  node 到底是不是 null，这个要看获取锁的过程，不过和这里都没有关系。
                //  如果不为 null，那就直接将它设置为链表表头；如果是null，初始化并设置为链表表头。
                if (node != null)
                    node.setNext(first);
                else
                    node = new HashEntry<K,V>(hash, key, value, first);
                
                //  这里的count是针对于当前Segment，也就是说count记录了当前Segment数组里面节点的总数。
                //  这里将count+1赋值给临时变量c，是为了避免后面的扩容或者是添加节点到表头出问题而导致的数据不一致现象。
                int c = count + 1;
                if (c > threshold && tab.length < MAXIMUM_CAPACITY)
                    //  如果c大于当前segment的阈值时，就扩容
                    rehash(node);
                else
                    //  否则将当前节点设置为表头
                    setEntryAt(tab, index, node);
                ++modCount;
                count = c;
                oldValue = null;
                break;
            }
        }
    } finally {
        //  解锁
        unlock();
    }
    return oldValue;
}
```

> 由于有独占锁的保护，所以segment内部的操作并不复杂。至于这里面的并发问题，我们后面在介绍。

到这里put操作就结束了，接下来，我们来详细看看其中一些关键的操作。

### <a id="init-segement-jdk7">初始化槽：ensureSegment</a>

这里可以考虑并发，因为可能会有多个线程对segment[k]进行初始化。

```java
private Segment<K,V> ensureSegment(int k) {
    final Segment<K,V>[] ss = this.segments;
    long u = (k << SSHIFT) + SBASE; // raw offset
    Segment<K,V> seg;

    //  先检查一下，当前Segment是否已经被初始化了
    if ((seg = (Segment<K,V>)UNSAFE.getObjectVolatile(ss, u)) == null) {

        //  以segment[0]作为其他segment的原型，这就是初始化的过程中要初始化segment[0]的原因
        Segment<K,V> proto = ss[0]; // use segment 0 as prototype
        int cap = proto.table.length;
        float lf = proto.loadFactor;
        int threshold = (int)(cap * lf);

        //  初始化segment[k]中的数组
        HashEntry<K,V>[] tab = (HashEntry<K,V>[])new HashEntry[cap];

        //  重复检查当前Segment是否已经被初始化了
        if ((seg = (Segment<K,V>)UNSAFE.getObjectVolatile(ss, u)) == null) { // recheck

            //  初始化当前Segment
            Segment<K,V> s = new Segment<K,V>(lf, threshold, tab);

            //  使用while循环检查当前Segment是否已经被初始化了
            while ((seg = (Segment<K,V>)UNSAFE.getObjectVolatile(ss, u)) == null) {
                //  只有当CAS成功交换，退出循环检查
                //  这个seg = s很灵性
                if (UNSAFE.compareAndSwapObject(ss, u, null, seg = s))
                    break;
            }
        }
    }
    return seg;
}
```

在并发环境，通过[CAS](./c-3.md)下来控制。

### <a id="get-entry-jdk7">获取链表：entryForHash</a>

在了解如何获取读写锁之前，我们先来看一下，ConcurrentHashMap是如何通过给定的segment和key的哈希码来获取链表的。

```java
static final <K,V> HashEntry<K,V> entryForHash(Segment<K,V> seg, int h) {
    HashEntry<K,V>[] tab;
    // 如果给定的segment未初始化或者是其指向的链表数组为初始化，那么返回null
    // 否则就根据key的哈希码来计算数组下标，获取对应的链表
    return (seg == null || (tab = seg.table) == null) ? null :
        (HashEntry<K,V>) UNSAFE.getObjectVolatile
        (tab, ((long)(((tab.length - 1) & h)) << TSHIFT) + TBASE);
}
```
### <a id="get-reentrantlock-jdk7">获取读写锁: scanAndLockForPut</a>

```java
HashEntry<K,V> node = tryLock() ? null : scanAndLockForPut(key, hash, value);
```

前面在调用segment.put方法的时候，会先去获取当前的segment的可重入锁。如果获取失败，那么进入到 `scanAndLockForput` 中，来获取读写锁。

```java
private HashEntry<K,V> scanAndLockForPut(K key, int hash, V value) {

    // 获取在当前segment中该hash对应的链表
    HashEntry<K,V> first = entryForHash(this, hash);
    HashEntry<K,V> e = first;
    HashEntry<K,V> node = null;
    int retries = -1; // negative while locating node

    // 循环试图获取当前segment的对象锁
    while (!tryLock()) {
        HashEntry<K,V> f; // to recheck first below
        if (retries < 0) {
            if (e == null) {
                if (node == null) // speculatively create node
                    // 如果代码执行到这里，说明当前数组的链表是空的，接着顺便初始化一下链表
                    // 同时也说明，当前这个segment存在竞争
                    node = new HashEntry<K,V>(hash, key, value, null);
                retries = 0;
            }
            else if (key.equals(e.key))
                retries = 0;
            else
                // 顺着链表往下走
                e = e.next;
        }
        //  MAX_SCAN_RETRIES 是根据当前的JVM的处理器个数来决定的，如果大于1，MAX_SCAN_RETRIES为 64， 否则为 1。
        else if (++retries > MAX_SCAN_RETRIES) {
            // 当retries大于最大重试次数，进入阻塞队列，等待锁
            // lock()是阻塞方法，直到获取锁之后返回
            lock();
            break;
        }
        else if ((retries & 1) == 0 &&
                    // 如果重试次数的最低位为1(其实就是重试次数为奇数)且当前这个链表已经发生变化时
                    // 将当前链表赋值给e和first，重设retries，重新进行scanAndLockForPut
                    (f = entryForHash(this, hash)) != first) {
            e = first = f; // re-traverse if entry changed
            retries = -1;
        }
    }
    return node;
}
```

这个方法有两个出口：

-   tryLock()成功，终止循环。
-   重试次数超过了MAX_SCAN_RETRIES，进入lock方法，此方法会阻塞等待，直到成功拿到独占锁。

### <a id="rehash-jdk7">扩容：rehash</a>

>   **重复一下**： segment数组不能扩容，扩容是 segment 数组某个位置内部的数组 HashEntry[] 进行扩容，扩容后，容量为原来的 2 倍。

在进行put操作的时候，如果当前segment的节点数加上当前要添加的节点的数量大于其阈值，那么进行扩容。

>   这里不需要考虑并发，因为执行到这里时，已经获取该segment的独占锁。

接下来看一下，rehash的细节。

```java
private void rehash(HashEntry<K,V> node) {

    // 将当前segment下的数组赋值给oldTable
    HashEntry<K,V>[] oldTable = table;
    int oldCapacity = oldTable.length;

    // 新的数组长度为旧的数组长度的2倍
    int newCapacity = oldCapacity << 1;

    // 重新计算阈值
    threshold = (int)(newCapacity * loadFactor);

    // 初始化新的数组
    HashEntry<K,V>[] newTable =
        (HashEntry<K,V>[]) new HashEntry[newCapacity];
    int sizeMask = newCapacity - 1;

    // 下面这个for循环看起来很复杂，其实就是做了一件事情：将旧table里面的所有节点迁移到新的table中
    for (int i = 0; i < oldCapacity ; i++) {
        //  e是oldTable[i]对应的链表的表头
        //  接下来就是遍历该链表里面的所有的节点
        HashEntry<K,V> e = oldTable[i];
        if (e != null) {
            // next为下一个节点
            HashEntry<K,V> next = e.next;
            // 计算新的数组下标
            int idx = e.hash & sizeMask;
            // 表明旧链表里面只有一个节点
            if (next == null)  
                newTable[idx] = e;
            else { 
                // 将链表表头赋值给lastRun
                HashEntry<K,V> lastRun = e;
                // 将头节点e的新下标赋值给lastIdx
                int lastIdx = idx;
                
                // 下面这个循环会找到一个lastRun节点，这个节点之后的所有元素是将要放在一起的
                for (HashEntry<K,V> last = next;
                        last != null;
                        last = last.next) {
                    int k = last.hash & sizeMask;
                    if (k != lastIdx) {
                        lastIdx = k;
                        lastRun = last;
                    }
                }

                // 将lastRun及其之后的所有节点组成的节点放入到lastIdx这个位置
                newTable[lastIdx] = lastRun;
                // 下面的操作是处理 lastRun之间的节点，
                // 这些即可能是分配到另一个链表中，也可能分配到上面那个链表中
                for (HashEntry<K,V> p = e; p != lastRun; p = p.next) {
                    V v = p.value;
                    int h = p.hash;
                    int k = h & sizeMask;
                    HashEntry<K,V> n = newTable[k];
                    newTable[k] = new HashEntry<K,V>(h, p.key, v, n);
                }
            }
        }
    }
    // 将新来的node放到刚刚的两个链表的其中一个中
    int nodeIndex = node.hash & sizeMask; // add the new node
    node.setNext(newTable[nodeIndex]);
    newTable[nodeIndex] = node;
    table = newTable;
}
```

### <a id="get-jdk7">get过程分析</a>

-   计算 hash 值，找到 segment 数组中的具体位置，或我们前面用的“槽”
-   槽中也是一个数组，根据 hash 找到数组中具体的位置
-   到这里是链表了，顺着链表进行查找即可

```java
public V get(Object key) {
    Segment<K,V> s; // manually integrate access methods to reduce overhead
    HashEntry<K,V>[] tab;

    // 计算key的哈希码
    int h = hash(key);
    long u = (((h >>> segmentShift) & segmentMask) << SSHIFT) + SBASE;
    // 根据哈希码获取相应的segment
    if ((s = (Segment<K,V>)UNSAFE.getObjectVolatile(segments, u)) != null &&
        (tab = s.table) != null) {
        
        // 获取链表并遍历
        for (HashEntry<K,V> e = (HashEntry<K,V>) UNSAFE.getObjectVolatile
                    (tab, ((long)(((tab.length - 1) & h)) << TSHIFT) + TBASE);
                e != null; e = e.next) {
            
            K k;
            if ((k = e.key) == key || (e.hash == h && key.equals(k)))
                return e.value;
        }
    }
    return null;
}
```

## <a id="position-segment">定位Segement</a>

如何获取Segment？ConcurrentHashMap在对Segment操作之前都需要对元素进行再散列。

![](/imgs/concurrency/c-1-4.png)

```java
private int hash(Object k) {
    int h = hashSeed;

    if ((0 != h) && (k instanceof String)) {
        return sun.misc.Hashing.stringHash32((String) k);
    }

    h ^= k.hashCode();

    // Spread bits to regularize both segment and index locations,
    // using variant of single-word Wang/Jenkins hash.
    h += (h <<  15) ^ 0xffffcd7d;
    h ^= (h >>> 10);
    h += (h <<   3);
    h ^= (h >>>  6);
    h += (h <<   2) + (h << 14);
    return h ^ (h >>> 16);
}
```

### 再散列的目的就是减少散列冲突

下面看个例子

```java
System.out.println(Integer.parseInt("0001111", 2) & 15);
System.out.println(Integer.parseInt("0011111", 2) & 15);
System.out.println(Integer.parseInt("0111111", 2) & 15);
System.out.println(Integer.parseInt("1111111", 2) & 15);
```

结果:

```txt
15
15
15
15
```

可见，只要低位一样，无论高位值是什么，其散列的结果总是一样的。

```java
public static int hash(int h) {
    h += (h <<  15) ^ 0xffffcd7d;
    h ^= (h >>> 10);
    h += (h <<   3);
    h ^= (h >>>  6);
    h += (h <<   2) + (h << 14);
    return h ^ (h >>> 16);
}

System.out.println(hash(Integer.parseInt("0001111", 2)));
System.out.println(hash(Integer.parseInt("0011111", 2)));
System.out.println(hash(Integer.parseInt("0111111", 2)));
System.out.println(hash(Integer.parseInt("1111111", 2)));
```

结果:

```txt
1197988430
-146603592
2003387966
-2097100774
```

经过再散列之后，数据就不会有冲突了。

### 定位Segment算法

```java
private Segment<K,V> segmentForHash(int h) {
    long u = (((h >>> segmentShift) & segmentMask) << SSHIFT) + SBASE;
    return (Segment<K,V>) UNSAFE.getObjectVolatile(segments, u);
}
```

### <a id="jdk7-summary">JDK7 总结</a>

1.  Segment数组是不可扩展的，Segment指向的链表数组是能够扩展的。
1.  ConcurrentHashMap是数组+链表的结构。
1.  初始化ConcurrentHashMap的时候，会初始化segment[0]。
    
    其segment[0]的作用就是为在ensureSegment方法中提供初始化数组长度和阈值的原型。

1.  初始化Segment是通过CAS方式来初始化的，此阶段存在资源竞争。

1.  put方法是线程安全的

    因为在进行put之前，会先去获取segment的对象锁。

##   参考
-   [占小狼](https://www.jianshu.com/p/c0642afe03e0)
-   《Java并发容器和框架》
-   [javadoop](https://javadoop.com/post/hashmap)

## [Back](../../summary.md)