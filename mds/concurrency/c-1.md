#   ConcurrentHashMap

##  为什么使用ConcurrentHashMap？

-   线程不安全的HashMap。在多线程下，对HashMap进行put操作会出现死循环。
-   HashTable的效率不高。一个线程在进行读写的时候，其他线程只能等待，其性能可想而知。

##  ConcurrentHashMap的原理

在ConcurrentHashMap中，有多个ReentrantLock，每一把锁都储存着一部分的数据。当多线程访问容器里不同数据段的时候，线程间就不会存在锁竞争。

##  ConcurrentHashMap的结构

**ConcurrentHashMap** 是由 **Segment** 数组结构和 **HashEntry** 数组结构组成。

-   Segment是ReentrantLock，在ConcurrentHashMap中扮演锁的角色。
-   HashEntry则用于 **储存** 键值对数据。

![](/imgs/concurrency/c-1-1.png)

## JDK1.7
-   [ConcurrentHashMap的初始化](#user-content-init-jdk7)
-   [put方法](#user-content-put-jdk7)
-   [定位Segment](#user-content-position-segment)

## <a id="init-jdk7">ConcurrentHashMap的初始化</a>

![](/imgs/concurrency/c-1-2.png)

我们就从ConcurrentHashMap的空构造方法开始深入了解其初始化过程。

```java
static final int DEFAULT_INITIAL_CAPACITY = 16;

static final float DEFAULT_LOAD_FACTOR = 0.75f;

static final int DEFAULT_CONCURRENCY_LEVEL = 16;

public ConcurrentHashMap() {
    this(DEFAULT_INITIAL_CAPACITY, DEFAULT_LOAD_FACTOR, DEFAULT_CONCURRENCY_LEVEL);
}
```

接着来看一下，**ConcurrentHashMap(int, float, int)** 初始化了哪些变量。

```java
public ConcurrentHashMap(int initialCapacity,float loadFactor,int concurrencyLevel) {
    if (!(loadFactor > 0) || initialCapacity < 0 || concurrencyLevel <= 0)
        throw new IllegalArgumentException();
    //  并发最大的等级为 2^16 = 65536
    if (concurrencyLevel > MAX_SEGMENTS)
        concurrencyLevel = MAX_SEGMENTS;
    //  Find power-of-two sizes best matching arguments

    int sshift = 0;
    //  ssize是Segment数组的长度，为2^n
    int ssize = 1;
    while (ssize < concurrencyLevel) {
        ++sshift;
        ssize <<= 1;
    }

    //  默认的concurrencyLevel为16
    //  sshift为4
    //  ssize为16
    //  segmentShift为28
    //  segmentMask为15
    this.segmentShift = 32 - sshift;
    this.segmentMask = ssize - 1;

    //  初始容量initialCapacity是用从来设置整个map的大小，最大为2^30
    if (initialCapacity > MAXIMUM_CAPACITY)
        initialCapacity = MAXIMUM_CAPACITY;

    //  c为ssize的倍数，且c*ssize >= initialCapacity。
    int c = initialCapacity / ssize;
    if (c * ssize < initialCapacity)
        ++c;

    //  cap为每个Segment可分配的链表个数，最少每个segment可以放2个链表，且链表的个数为2^n(n >= 1)。
    int cap = MIN_SEGMENT_TABLE_CAPACITY;
    while (cap < c)
        cap <<= 1;

    // create segments and segments[0]
    Segment<K,V> s0 =
        new Segment<K,V>(loadFactor, (int)(cap * loadFactor),
                            (HashEntry<K,V>[])new HashEntry[cap]);
    Segment<K,V>[] ss = (Segment<K,V>[])new Segment[ssize];

    // 往数组写入 segment[0]
    UNSAFE.putOrderedObject(ss, SBASE, s0); // ordered write of segments[0]
    this.segments = ss;
}
```

-   初始化三个变量：
    -   段偏移量segementShift
    -   段掩码segementMask
    -   segment数组(不可扩容)
    -   segment[0]

segment数组的长度是由 `ssize` 来决定的其长度的。 `ssize` 是由concurrencyLevel(并发等级) 来决定。 这里的concurrencyLevel为16,所以 `sshift` 为4， `ssize` 为16，即这里的segment数组的长度为16，  `segmentShift` 为28， `segmentMask` 为15。

## <a id="put-jdk7">put</a>

```java
public V put(K key, V value) {
    Segment<K,V> s;

    //  value不能为null
    if (value == null)
        throw new NullPointerException();
    
    //  计算key的哈希码
    int hash = hash(key);

    int j = (hash >>> segmentShift) & segmentMask;
    if ((s = (Segment<K,V>)UNSAFE.getObject(segments, (j << SSHIFT) + SBASE)) == null) //  in ensureSegment
        // 初始化segment[j]
        s = ensureSegment(j);
    
    //  往初始化的segment里面添加节点
    return s.put(key, hash, value, false);
}
```

第一层，根据hash值很快就能找到相应的segment，之后就是segment内部的put操作。

```java
final V put(K key, int hash, V value, boolean onlyIfAbsent) {
    // 先获取该segment的独占锁，稍后会详解
    HashEntry<K,V> node = tryLock() ? null : scanAndLockForPut(key, hash, value);
    V oldValue;
    try {
        //  这个table就是前面构造函数中初始化的segment[j]里面的数组长度。
        HashEntry<K,V>[] tab = table;
        //  再利用hash，求该key所应该存放的数组下标位置
        int index = (tab.length - 1) & hash;
        //  获取index值下所对应的链表的表头
        HashEntry<K,V> first = entryAt(tab, index);
        //  下面进行是对链表存在和链表不存在的情况下，进行put操作
        for (HashEntry<K,V> e = first;;) {
            //  当链表存在时
            if (e != null) {
                K k;
                //  如果key已经存在，将已存在的值返回。同时将新的value覆盖掉旧的value。
                if ((k = e.key) == key ||
                    (e.hash == hash && key.equals(k))) {
                    oldValue = e.value;
                    if (!onlyIfAbsent) {
                        e.value = value;
                        ++modCount;
                    }
                    break;
                }

                //  遍历链表下一个
                e = e.next;
            }
            else {
                //  node 到底是不是 null，这个要看获取锁的过程，不过和这里都没有关系。
                //  如果不为 null，那就直接将它设置为链表表头；如果是null，初始化并设置为链表表头。
                if (node != null)
                    node.setNext(first);
                else
                    node = new HashEntry<K,V>(hash, key, value, first);
                
                //  这里的count是针对于整个Segment数组的，也就是说count记录了Segment数组里面节点的总数。
                //  这里将count+1赋值给临时变量c，是为了避免后面的扩容或者是添加节点到表头出问题而导致的数据不一致现象。
                int c = count + 1;
                if (c > threshold && tab.length < MAXIMUM_CAPACITY)
                    //  如果c大于当前segment的阈值时，就扩容
                    rehash(node);
                else
                    //  否则将当前节点设置为表头
                    setEntryAt(tab, index, node);
                ++modCount;
                count = c;
                oldValue = null;
                break;
            }
        }
    } finally {
        //  解锁
        unlock();
    }
    return oldValue;
}
```

> 由于有独占锁的保护，所以segment内部的操作并不复杂。至于这里面的并发问题，我们后面在介绍。

到这里put操作就结束了，接下来，我们来详细看看其中一些关键的操作。

### 初始化槽：ensureSegment

```java
private Segment<K,V> ensureSegment(int k) {
    final Segment<K,V>[] ss = this.segments;
    long u = (k << SSHIFT) + SBASE; // raw offset
    Segment<K,V> seg;

    //  先检查一下，当前Segment是否已经被初始化了
    if ((seg = (Segment<K,V>)UNSAFE.getObjectVolatile(ss, u)) == null) {

        //  以segment[0]作为其他segment的原型，这就是初始化的过程中要初始化segment[0]的原因
        Segment<K,V> proto = ss[0]; // use segment 0 as prototype
        int cap = proto.table.length;
        float lf = proto.loadFactor;
        int threshold = (int)(cap * lf);

        //  初始化segment[k]中的数组
        HashEntry<K,V>[] tab = (HashEntry<K,V>[])new HashEntry[cap];

        //  重复检查当前Segment是否已经被初始化了
        if ((seg = (Segment<K,V>)UNSAFE.getObjectVolatile(ss, u)) == null) { // recheck

            //  初始化当前Segment
            Segment<K,V> s = new Segment<K,V>(lf, threshold, tab);

            //  使用while循环检查当前Segment是否已经被初始化了
            while ((seg = (Segment<K,V>)UNSAFE.getObjectVolatile(ss, u)) == null) {
                //  只有当CAS成功交换，退出循环检查
                //  这个seg = s很灵性
                if (UNSAFE.compareAndSwapObject(ss, u, null, seg = s))
                    break;
            }
        }
    }
    return seg;
}
```

## <a id="position-segment">定位Segement</a>

如何获取Segment？ConcurrentHashMap在对Segment操作之前都需要对元素进行再散列。

![](/imgs/concurrency/c-1-4.png)

```java
private int hash(Object k) {
    int h = hashSeed;

    if ((0 != h) && (k instanceof String)) {
        return sun.misc.Hashing.stringHash32((String) k);
    }

    h ^= k.hashCode();

    // Spread bits to regularize both segment and index locations,
    // using variant of single-word Wang/Jenkins hash.
    h += (h <<  15) ^ 0xffffcd7d;
    h ^= (h >>> 10);
    h += (h <<   3);
    h ^= (h >>>  6);
    h += (h <<   2) + (h << 14);
    return h ^ (h >>> 16);
}
```

### 再散列的目的就是减少散列冲突

下面看个例子

```java
System.out.println(Integer.parseInt("0001111", 2) & 15);
System.out.println(Integer.parseInt("0011111", 2) & 15);
System.out.println(Integer.parseInt("0111111", 2) & 15);
System.out.println(Integer.parseInt("1111111", 2) & 15);
```

结果:

```txt
15
15
15
15
```

可见，只要低位一样，无论高位值是什么，其散列的结果总是一样的。

```java
public static int hash(int h) {
    h += (h <<  15) ^ 0xffffcd7d;
    h ^= (h >>> 10);
    h += (h <<   3);
    h ^= (h >>>  6);
    h += (h <<   2) + (h << 14);
    return h ^ (h >>> 16);
}

System.out.println(hash(Integer.parseInt("0001111", 2)));
System.out.println(hash(Integer.parseInt("0011111", 2)));
System.out.println(hash(Integer.parseInt("0111111", 2)));
System.out.println(hash(Integer.parseInt("1111111", 2)));
```

结果:

```txt
1197988430
-146603592
2003387966
-2097100774
```

经过再散列之后，数据就不会有冲突了。

### 定位Segment算法

```java
private Segment<K,V> segmentForHash(int h) {
    long u = (((h >>> segmentShift) & segmentMask) << SSHIFT) + SBASE;
    return (Segment<K,V>) UNSAFE.getObjectVolatile(segments, u);
}
```

##   参考
-   [占小狼](https://www.jianshu.com/p/c0642afe03e0)
-   《Java并发容器和框架》
-   [importnew](http://www.importnew.com/28263.html)

## [Back](../../summary.md)